{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aFHUYfO2igoq"
      },
      "source": [
        "# Introduction to Bio Medical Image Preprocessing, Segmentation.\n",
        "\n",
        "[Image 1 download](https://s3.amazonaws.com/bebi103.caltech.edu/data/bsub_100x_phase.tif), [Image 2 download](https://s3.amazonaws.com/bebi103.caltech.edu/data/bsub_100x_cfp.tif)\n",
        "\n",
        "<hr>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-dlDc9Pxigou"
      },
      "outputs": [],
      "source": [
        "# Colab setup ------------------\n",
        "import os, sys, subprocess\n",
        "if \"google.colab\" in sys.modules:\n",
        "    cmd = \"pip install --upgrade bebi103 iqplot scikit-image watermark\"\n",
        "    process = subprocess.Popen(cmd.split(), stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "    stdout, stderr = process.communicate()\n",
        "    data_path = \"https://s3.amazonaws.com/bebi103.caltech.edu/data/\"\n",
        "else:\n",
        "    data_path = \"../data/\"\n",
        "# ------------------------------\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Our image processing tools\n",
        "import skimage.filters\n",
        "import skimage.io\n",
        "import skimage.morphology\n",
        "\n",
        "import bebi103\n",
        "import iqplot\n",
        "\n",
        "import bokeh.layouts\n",
        "import bokeh.io\n",
        "\n",
        "bokeh.io.output_notebook()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_m4JV6aQigow"
      },
      "source": [
        "<hr>\n",
        "\n",
        "In this lesson, we will learn some basic techniques for image processing using [scikit-image](http://scikit-image.org) with Python."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "us6bn-D-igox"
      },
      "source": [
        "## Loading and viewing images\n",
        "\n",
        "We will now load and view the test images we will use for segmentation.  We load the image using the `skimage.io.imread()`.  The image is stored as a NumPy array.  Each entry in the array is a pixel value.  This is an important point: **a digital image is data**!  It is a set of numbers with spatial positions.\n",
        "\n",
        "Today, we'll be looking at some images of  *Bacillus subtilis*, a gram-positive bacterium famous for its ability to enter [a form of \"suspended animation\" known as sporulation](https://en.wikipedia.org/wiki/Sporulation_in_Bacillus_subtilis) when environmental conditions get rough. In these images, all cells have been engineered to express Cyan Fluorescent Protein (CFP) once they enter a particular genetic state known as [competence](https://en.wikipedia.org/wiki/Natural_competence). These cells have been imaged under phase contrast (`bsub_100x_phase.tif`) and epifluorescence (`bsub_100x_cfp.tif`) microscopy. These images were acquired by former Caltech graduate student [Griffin Chure](https://gchure.github.io).\n",
        "\n",
        "Let's go ahead and load an image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qortI9kqigoy"
      },
      "outputs": [],
      "source": [
        "# Load the phase contrast image.\n",
        "im_phase = skimage.io.imread(os.path.join(data_path, 'bsub_100x_phase.tif'))\n",
        "\n",
        "# Take a look\n",
        "im_phase"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5Rw84qQigoy"
      },
      "source": [
        "We indeed have a NumPy array of integer values. To properly display images, we also need to specify the **interpixel distance**, the physical distance corresponding to neighboring pixels in an image. Interpixel distances are calibrated for an optical setup by various means. For this particular setup, the interpixel distance was 62.6 nm."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1GHUzXGGigoz"
      },
      "outputs": [],
      "source": [
        "# Store the interpixel distance in units of microns\n",
        "ip_distance = 0.0626"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NaeXuuZbigoz"
      },
      "source": [
        "Now that we have the image loaded, and know the interpixel distance, we would like to view it. Really, I should say \"plot it\" because, *an image is data*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0PNDs2dPigo0"
      },
      "source": [
        "### Viewing images with Bokeh and bebi103\n",
        "\n",
        "The `bebi103.viz.imshow()` function enables easy viewing of images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_oGclQfyigo0"
      },
      "outputs": [],
      "source": [
        "# Create a rendering of the image\n",
        "p = bebi103.image.imshow(im_phase)\n",
        "\n",
        "# Use bokeh to display\n",
        "bokeh.io.show(p)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nYXhlZwKigo0"
      },
      "source": [
        "The image is displayed with the bebi103 default colormap (more on that in a moment). By default, the axes are in units of pixels. We would rather have the axes marked in units of microns so we know the physical distances. We can specify that with the `interpixel_distance` keyword argument for `bebi103.image`. We can make that for this image using our value of the interpixel distance.\n",
        "\n",
        "To demonstrate additional options, we will set the height of the image as displayed to be 200 pixels and a grayscale colormap, which we can do with the `frame_height` and `cmap` keyword arguments, respectively."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ceAvCYHvigo0"
      },
      "outputs": [],
      "source": [
        "p1 = bebi103.image.imshow(\n",
        "    im_phase,\n",
        "    frame_height=200,\n",
        "    interpixel_distance=ip_distance,\n",
        "    cmap=bokeh.palettes.gray(256),\n",
        "    x_axis_label=\"µm\",\n",
        "    y_axis_label=\"µm\",\n",
        ")\n",
        "\n",
        "bokeh.plotting.show(p1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SorE_Mm4igo1"
      },
      "source": [
        "Conveniently, the image is fully interactive; we can zoom to our heart's content."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqafhWEMigo1"
      },
      "source": [
        "## Lookup tables\n",
        "\n",
        "\n",
        "In the above image, we used a gray colormap. Following are a few different colormaps we could use instead. As I discuss momentarily, you will *almost always* want to use Viridis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uy02TjtAigo1"
      },
      "outputs": [],
      "source": [
        "p2 = bebi103.image.imshow(\n",
        "    im_phase,\n",
        "    frame_height=200,\n",
        "    cmap=bokeh.palettes.magma(256),\n",
        "    interpixel_distance=ip_distance,\n",
        "    x_axis_label=\"µm\",\n",
        "    y_axis_label=\"µm\",\n",
        ")\n",
        "\n",
        "\n",
        "p3 = bebi103.image.imshow(\n",
        "    im_phase,\n",
        "    frame_height=200,\n",
        "    cmap=bokeh.palettes.viridis(256),\n",
        "    interpixel_distance=ip_distance,\n",
        "    x_axis_label=\"µm\",\n",
        "    y_axis_label=\"µm\",\n",
        ")\n",
        "\n",
        "p4 = bebi103.image.imshow(\n",
        "    im_phase,\n",
        "    frame_height=200,\n",
        "    cmap=bokeh.palettes.turbo(256),\n",
        "    interpixel_distance=ip_distance,\n",
        "    x_axis_label=\"µm\",\n",
        "    y_axis_label=\"µm\",\n",
        ")\n",
        "\n",
        "# make a grid\n",
        "grid = bokeh.layouts.gridplot([[p1, p2], [p3, p4]])\n",
        "\n",
        "bokeh.io.show(grid)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PyMjyao6igo1"
      },
      "source": [
        "The axis of the above images don't connect unless that is explicitly directed. To connect them so that zoomed regions are similar, we can use the following code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YFZFnfBLigo1"
      },
      "outputs": [],
      "source": [
        "#Set the ranges for each plot equal to one another, so that they zoom to the same region\n",
        "p2.x_range = p1.x_range\n",
        "p2.y_range = p1.y_range\n",
        "p3.x_range = p1.x_range\n",
        "p3.y_range = p1.y_range\n",
        "p4.x_range = p1.x_range\n",
        "p4.y_range = p1.y_range\n",
        "\n",
        "bokeh.io.show(grid)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9zZjxIQigo1"
      },
      "source": [
        "In image processing, a colormap is called a **lookup table** (LUT). A LUT is a mapping of pixel values to a color. This sometimes helps visualize images, especially when we use false coloring. Remember, a digital image is data, and false coloring an image is **not** manipulation of data. It is simply a different way of plotting it.\n",
        "\n",
        "As we just saw, we specify a lookup table with a **colormap**. There is lots of debate about that the best colormaps (LUTs) are. The data visualization community seems to universally reject using rainbow colormaps. See, e.g., [D. Borland and R. M. Taylor, Rainbow Color Map (Still) Considered Harmful, IEEE Computer Graphics and Applications, 27,14-17, 2007](http://doi.ieeecomputersociety.org/10.1109/MCG.2007.46). In the lower right example, I use a rainbow colorscale. You can see how the brightest parts of the image are not the ones that have the highest values. The rainbow colormaps (as discussed in the above publication, have issues with colorblind accessability and data emphasis. You should **NOT** use rainbow colormaps.\n",
        "\n",
        "Viridis [has been designed](http://bids.github.io/colormap/) to be perceptually flat across a large range of values.\n",
        "\n",
        "Importantly, the false coloring helps use see that the intensity of the pixel values in the middle of cell clusters are similar to those of the background which will become an issue, as we will see, as we begin our segmentation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nWOi_Er7igo1"
      },
      "source": [
        "## Introductory segmentation\n",
        "\n",
        "As mentioned before, **segmentation** is the process by which we separate regions of an image according to their identity for easier analysis. E.g., if we have an image of bacteria and we want to determine what is \"bacteria\" and what is \"not bacteria,\" we would do some segmentation. We will use bacterial test images for this purpose."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TRLb7MRhigo1"
      },
      "source": [
        "### Histograms\n",
        "\n",
        "As we begin segmentation, remember that viewing an image is just a way of plotting the digital image data.  We can also plot a **histogram**, where we plot the number of pixels with a given value against pixel values. This helps use see some patterns in the pixel values and is often an important first step toward segmentation.\n",
        "\n",
        "The histogram of an image is simply a list of counts of pixel values. When we plot the histogram, we can often readily see breaks in which pixel values are most frequently encountered. There are many ways of looking at histograms. The `spike()` function of iqplot can be used to conveniently display a histogram,"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O83OSNcIigo2"
      },
      "outputs": [],
      "source": [
        "p = iqplot.spike(\n",
        "    data=im_phase.flatten(),\n",
        "    q='intensity',\n",
        "    style='spike',\n",
        ")\n",
        "\n",
        "bokeh.io.show(p)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Wgza6SKigo2"
      },
      "source": [
        "We see that there are is some structure in the histogram of the phase image. While our eyes are drawn to the large peak around 380, we should keep in mind that our bacteria are black on a bright background and occupy only a small area of the image. We can see a smaller peak in the vicinity of 200 which likely represent our bugs of interest. The peak to the right is brighter, so likely represents the background. Therefore, if we can find where the valley between the two peaks is, we may take pixels with intensity below that value to be bacteria and those above to be background. Eyeballing it, I think this critical pixel value is about 300."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZgBZuv6zigo2"
      },
      "source": [
        "### Thresholding\n",
        "\n",
        "The process of taking pixels above or below a certain value is called **thresholding**. It is one of the simplest ways to segment an image. We call every pixel with a value below 300 part of a bacterium and everything above *not* part of a bacterium."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LoS5tZjYigo2"
      },
      "outputs": [],
      "source": [
        "# Threshold value, as obtained by eye\n",
        "thresh_phase = 300\n",
        "\n",
        "# Generate thresholded image\n",
        "im_phase_bw = im_phase < thresh_phase\n",
        "\n",
        "# Display phase and thresholded image\n",
        "p1 = bebi103.image.imshow(\n",
        "    im_phase,\n",
        "    frame_height=200,\n",
        "    interpixel_distance=ip_distance,\n",
        "    x_axis_label=\"µm\",\n",
        "    y_axis_label=\"µm\",\n",
        ")\n",
        "\n",
        "p2 = bebi103.image.imshow(\n",
        "    im_phase_bw,\n",
        "    frame_height=200,\n",
        "    interpixel_distance=ip_distance,\n",
        "    x_axis_label=\"µm\",\n",
        "    y_axis_label=\"µm\",\n",
        "    cmap=[\"black\", \"white\"],\n",
        ")\n",
        "\n",
        "p2.x_range = p1.x_range\n",
        "p2.y_range = p1.y_range\n",
        "\n",
        "plots = [p1, p2]\n",
        "\n",
        "bokeh.io.show(bokeh.layouts.row(plots))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WrO_DHevigo2"
      },
      "source": [
        "We can overlay these images to get a good view.  To do this, we will make an RGB image, and saturate the green channel where the thresholded image is white. We can then display it at an RGB image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wOEwj7JJigo2"
      },
      "outputs": [],
      "source": [
        "# Build RGB image by stacking grayscale images\n",
        "im_phase_rgb = np.dstack(3 * [im_phase / im_phase.max()])\n",
        "\n",
        "# Saturate green channel wherever there are white pixels in thresh image\n",
        "im_phase_rgb[im_phase_bw, 1] = 1.0\n",
        "\n",
        "# Show the result\n",
        "bokeh.io.show(bebi103.image.imshow(im_phase_rgb))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDh1Gbs0igo2"
      },
      "source": [
        "We see that we did a decent job finding bacteria, but we also pick up quite a bit of garbage sitting around the cells. We can also see that in some of the bigger clusters, we do not effectively label the bacteria in the middle of colonies. This is because of the \"halo\" of high intensity signal near boundaries of the bacteria that we get from using phase contrast microscopy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xBfbst_Migo3"
      },
      "source": [
        "### Using the CFP channel\n",
        "\n",
        "One way around these issues is to use bacteria that constitutively express a fluorescent protein and to segment in using the fluorescent channel. Let's try the same procedure with the CFP channel. First, let's look at the image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vWHbcW5vigo3"
      },
      "outputs": [],
      "source": [
        "# Load image\n",
        "im_cfp = skimage.io.imread(os.path.join(data_path, \"bsub_100x_cfp.tif\"))\n",
        "\n",
        "# Display the image\n",
        "bokeh.io.show(bebi103.image.imshow(im_cfp))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8O3mx5UAigo3"
      },
      "source": [
        "We see that the bacteria are typically brighter than the background (which is impressively uniform), so this might help us in segmentation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L25QD2b-igo3"
      },
      "source": [
        "### Filtering noise: the median filter\n",
        "\n",
        "While it may not be obvious from this image, the non-bacterial pixels are not completely dark due to autofluorescence of the immobilization substrate as well as some issues in our camera. In fact, the camera on which these images were acquired has a handful of \"bad\" pixels which are always much higher than the \"real\" value. This could cause issues in situations where we would want to make quantitative measurements of intensity. We can zoom in on one of these \"bad\" pixels below (ignoring in the display below the axes)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pU5RnUx6igo3"
      },
      "outputs": [],
      "source": [
        "bokeh.io.show(bebi103.image.imshow(im_cfp[150:250, 450:550]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aepBo87uigo3"
      },
      "source": [
        "We see a single bright pixel. In addition to throwing off our colormap a bit, this could alter the measured intensity of a cell if there happen to be any other bad pixels hiding within the bacteria. We can remove this noise by using a **median filter**. The concept is simple. We take a shape of pixels, called a **structuring element**, and pass it over the image. The value of the center pixel in the max is replaced by the median value of all pixels in the mask. To do this, we first need to construct a mask. This is done using the `skimage.morphology` module. The filtering is then done using `skimage.filters.rank.median()`. Let’s try it with a 3$\\times$3 square mask."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RLlhiXUvigo3"
      },
      "outputs": [],
      "source": [
        "# Make the structuring element\n",
        "selem = skimage.morphology.square(3)\n",
        "\n",
        "# Perform the median filter\n",
        "im_cfp_filt = skimage.filters.median(im_cfp, selem)\n",
        "\n",
        "# Display image\n",
        "bokeh.io.show(bebi103.image.imshow(im_cfp_filt))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xVrTvHYHigo3"
      },
      "source": [
        "Now that we have dealt with the noisy pixels, we can now see more clearly that some cells are very bright compared with others."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EyVK90NJigo3"
      },
      "source": [
        "### Thresholding in the CFP channel\n",
        "\n",
        "We'll proceed by plotting the histogram and finding the threshold value."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s0C8xLGqigo3"
      },
      "outputs": [],
      "source": [
        "p = iqplot.spike(\n",
        "    data=im_cfp_filt.flatten(),\n",
        "    q=\"intensity\",\n",
        "    style=\"spike\",\n",
        ")\n",
        "\n",
        "bokeh.io.show(p)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OldT1Abzigo3"
      },
      "source": [
        "Yeesh. There are lots of bright pixels, but it is kind of hard to see where (or even if) there is valley in the histogram. It sometimes helps to plot the histogram with the y-axis on a log scale. When we do this, we can eyeball the threshold value to be about 140."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GMhJJe8Uigo8"
      },
      "outputs": [],
      "source": [
        "# Use style='dot' when using a log scale, since there is no zero\n",
        "p = iqplot.spike(\n",
        "    data=im_cfp_filt.flatten(),\n",
        "    q=\"intensity\",\n",
        "    style=\"dot\",\n",
        "    y_axis_type=\"log\",\n",
        "    y_range=[1e2, 1e6],\n",
        ")\n",
        "\n",
        "bokeh.io.show(p)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YsRKMMS5igo8"
      },
      "source": [
        "Now let's try thresholding the image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TGGIhXQuigo8"
      },
      "outputs": [],
      "source": [
        "# Threshold value, as obtained by eye\n",
        "thresh_cfp = 140\n",
        "\n",
        "# Generate thresholded image\n",
        "im_cfp_bw = im_cfp_filt > thresh_cfp\n",
        "\n",
        "# Display\n",
        "plots = [\n",
        "    bebi103.image.imshow(im_cfp, frame_height=200),\n",
        "    bebi103.image.imshow(im_cfp_bw, frame_height=200, cmap=['black', 'white'])\n",
        "]\n",
        "\n",
        "bokeh.io.show(bokeh.layouts.row(plots))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nE1ZypNUigo8"
      },
      "source": [
        "Looks like we're doing much better!  Let's try overlapping the images now."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0YVXUdO7igo8"
      },
      "outputs": [],
      "source": [
        "# Build RGB image by stacking grayscale images\n",
        "im_rgb = np.dstack(3 * [im_phase / im_phase.max()])\n",
        "\n",
        "# Saturate green channel wherever there are white pixels in thresh image\n",
        "im_rgb[im_cfp_bw, 1] = 1.0\n",
        "\n",
        "# Show the result\n",
        "bokeh.io.show(bebi103.image.imshow(im_rgb))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OoG4haY6igo8"
      },
      "source": [
        "Very nice! In general, it is often much easier to segment bacteria with fluorescence."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVAuGxiJigo9"
      },
      "source": [
        "### Otsu's method for thresholding\n",
        "\n",
        "It turns out that there is an automated way to find the threshold value, as opposed to eyeballing it like we have been doing. [Otsu's method](https://en.wikipedia.org/wiki/Otsu%27s_method) provides this functionality."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n3gzilX3igo9"
      },
      "outputs": [],
      "source": [
        "# Compute Otsu thresholds for phase and cfp\n",
        "thresh_phase_otsu = skimage.filters.threshold_otsu(im_phase)\n",
        "thresh_cfp_otsu = skimage.filters.threshold_otsu(im_cfp_filt)\n",
        "\n",
        "# Compare results to eyeballing it\n",
        "print(\"Phase by eye: \", thresh_phase, \"   CFP by eye: \", thresh_cfp)\n",
        "print(\"Phase by Otsu:\", thresh_phase_otsu, \"   CFP by Otsu:\", thresh_cfp_otsu)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5NaDNWOpigo9"
      },
      "source": [
        "We see that for the CFP channel, the Otsu method did very well. However, for phase, we see a big difference. This is because the Otsu method assumes a bimodal distribution of pixels. If we look at the histograms on a log scale, we see more clearly that the phase image has a long tail, which will trip up the Otsu algorithm. The moral of the story is that you can use automated thresholding, but you should always do sanity checks to make sure it is working as expected."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Sx0XmX-igo9"
      },
      "source": [
        "## Determining the bacterial area\n",
        "\n",
        "Now that we have a thresholded image, we can determine the total area taken up by bacteria.  It's as simple as summing up the pixel values of the thresholded image!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EtcLk02_igo9"
      },
      "outputs": [],
      "source": [
        "# Compute bacterial area\n",
        "bacterial_area_pix = (im_cfp_filt > thresh_cfp_otsu).sum()\n",
        "\n",
        "# Print out the result\n",
        "print(\"bacterial area =\", bacterial_area_pix, \"pixels\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dsAhgV8igo9"
      },
      "source": [
        "If we want to get the total area that is bacterial in units of µm, we could use the interpixel distances to get the area represented by each pixel. For this setup, the interpixel distance is 0.0636 µm. We can then compute the bacterial area as follows."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UBf-aSzKigo9"
      },
      "outputs": [],
      "source": [
        "# Compute bacterial area\n",
        "bacterial_area_micron = bacterial_area_pix * ip_distance**2\n",
        "\n",
        "# Print total area\n",
        "print('bacterial area =', bacterial_area_micron, 'square microns')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgtOz1sOigo9"
      },
      "source": [
        "## Computing environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bfzHo-moigo9"
      },
      "outputs": [],
      "source": [
        "%load_ext watermark\n",
        "%watermark -v -p numpy,skimage,bokeh,iqplot,bebi103,jupyterlab"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}